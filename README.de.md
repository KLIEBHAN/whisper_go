# whisper_go

[![Tests](https://github.com/KLIEBHAN/whisper_go/actions/workflows/test.yml/badge.svg)](https://github.com/KLIEBHAN/whisper_go/actions/workflows/test.yml)
[![codecov](https://codecov.io/gh/KLIEBHAN/whisper_go/graph/badge.svg)](https://codecov.io/gh/KLIEBHAN/whisper_go)

[ðŸ‡ºðŸ‡¸ English Version](README.md)

Spracheingabe fÃ¼r macOS â€“ inspiriert von [Wispr Flow](https://wisprflow.ai). Transkribiert Audio mit OpenAI Whisper Ã¼ber API, Deepgram, Groq oder lokal.

**Features:** Echtzeit-Streaming (Deepgram) Â· Mehrere Provider (OpenAI, Deepgram, Groq, lokal inkl. MLX/Metal auf Apple Silicon) Â· LLM-Nachbearbeitung Â· Kontext-Awareness Â· Custom Vocabulary Â· Raycast-Hotkeys Â· Live-Preview Overlay Â· MenÃ¼bar-Feedback

> **Performance:** Ultra-Fast-Startup mit ~170ms bis Ready-Sound dank parallelem Mikrofon- und WebSocket-Init. Audio wird wÃ¤hrend der Aufnahme transkribiert â€“ Ergebnis erscheint sofort nach dem Stoppen.

### Provider im Ãœberblick

| Provider     | Latenz    | Methode   | Besonderheit                  |
| ------------ | --------- | --------- | ----------------------------- |
| **Deepgram** | ~300ms âš¡ | WebSocket | Echtzeit-Streaming, empfohlen |
| **Groq**     | ~1s       | REST      | Whisper auf LPU, sehr schnell |
| **OpenAI**   | ~2-3s     | REST      | GPT-4o, hÃ¶chste QualitÃ¤t      |
| **Lokal**    | variiert  | Whisper   | Offline, keine API-Kosten (MLX/Metal auf Apple Silicon) |

## Schnellstart

In unter 2 Minuten einsatzbereit:

```bash
# 1. Repository klonen
git clone https://github.com/KLIEBHAN/whisper_go.git && cd whisper_go

# 2. Dependencies installieren
pip install -r requirements.txt

# 3. API-Key setzen (Deepgram: 200$ Startguthaben)
export DEEPGRAM_API_KEY="dein_key"

# 4. Erste Aufnahme
python transcribe.py --record --copy --mode deepgram
```

### Empfohlene `.env` Konfiguration

WhisperGo lÃ¤dt Einstellungen aus `~/.whisper_go/.env` (empfohlen; wird von Settings-UI und Daemon genutzt).  
FÃ¼r Development wird zusÃ¤tzlich eine lokale `.env` im Projektverzeichnis unterstÃ¼tzt.

```bash
# Empfohlen (funktioniert fÃ¼r Daemon / App Bundle)
cp .env.example ~/.whisper_go/.env
```

Beispiel `~/.whisper_go/.env`:

```bash
# API-Keys
DEEPGRAM_API_KEY=...
GROQ_API_KEY=...
OPENAI_API_KEY=...
OPENROUTER_API_KEY=...

# Transkription
WHISPER_GO_MODE=deepgram
WHISPER_GO_LANGUAGE=de

# LLM-Nachbearbeitung
WHISPER_GO_REFINE=true
WHISPER_GO_REFINE_PROVIDER=groq
WHISPER_GO_REFINE_MODEL=openai/gpt-oss-120b
```

**Warum diese Einstellungen?**

| Einstellung                        | BegrÃ¼ndung                                             |
| ---------------------------------- | ------------------------------------------------------ |
| `MODE=deepgram`                    | Schnellste Option (~300ms) durch WebSocket-Streaming   |
| `REFINE_PROVIDER=groq`             | Kostenlose/gÃ¼nstige LLM-Inferenz auf LPU-Hardware      |
| `REFINE_MODEL=openai/gpt-oss-120b` | Open-Source GPT-Alternative mit exzellenter QualitÃ¤t   |
| `LANGUAGE=de`                      | Explizite Sprache verbessert Transkriptionsgenauigkeit |

> **Tipp:** FÃ¼r systemweite Hotkeys siehe [Hotkey Integration](#hotkey-integration).

## CLI-Nutzung

Zwei Hauptfunktionen: Audiodateien transkribieren oder direkt vom Mikrofon aufnehmen.

### Audiodatei transkribieren

```bash
python transcribe.py audio.mp3                        # Standard (API-Modus)
python transcribe.py audio.mp3 --mode openai          # OpenAI GPT-4o Transcribe
python transcribe.py audio.mp3 --mode deepgram        # Deepgram Nova-3
python transcribe.py audio.mp3 --mode groq            # Groq (schnellste Option)
python transcribe.py audio.mp3 --mode local           # Offline mit lokalem Whisper
```

### Mikrofon-Aufnahme

```bash
python transcribe.py --record                         # Aufnehmen und ausgeben
python transcribe.py --record --copy                  # Direkt in Zwischenablage
python transcribe.py --record --refine                # Mit LLM-Nachbearbeitung
```

**Workflow:** Enter â†’ Sprechen â†’ Enter â†’ Transkript erscheint

### Alle Optionen

| Option                                 | Beschreibung                                                                  |
| -------------------------------------- | ----------------------------------------------------------------------------- |
| `--mode openai\|local\|deepgram\|groq` | Transkriptions-Provider (default: `openai`)                                   |
| `--model NAME`                         | Modell (CLI > `WHISPER_GO_MODEL` env > Provider-Default)                      |
| `--record`, `-r`                       | Mikrofon-Aufnahme statt Datei                                                 |
| `--copy`, `-c`                         | Ergebnis in Zwischenablage                                                    |
| `--language CODE`                      | Sprachcode z.B. `de`, `en`                                                    |
| `--format FORMAT`                      | Output: `text`, `json`, `srt`, `vtt` (nur API-Modus)                          |
| `--no-streaming`                       | WebSocket-Streaming deaktivieren (nur Deepgram)                               |
| `--refine`                             | LLM-Nachbearbeitung aktivieren                                                |
| `--no-refine`                          | LLM-Nachbearbeitung deaktivieren (Ã¼berschreibt env)                           |
| `--refine-model`                       | Modell fÃ¼r Nachbearbeitung (default: `gpt-5-nano`)                            |
| `--refine-provider`                    | LLM-Provider: `openai`, `openrouter`, `groq`                                  |
| `--context`                            | Kontext fÃ¼r Nachbearbeitung: `email`, `chat`, `code`, `default` (auto-detect) |

## Konfiguration

Alle Einstellungen kÃ¶nnen per Umgebungsvariable oder `.env`-Datei gesetzt werden. CLI-Argumente haben immer Vorrang.

### API-Keys

Je nach gewÃ¤hltem Modus wird ein API-Key benÃ¶tigt:

```bash
# OpenAI (fÃ¼r --mode openai und --refine mit openai)
export OPENAI_API_KEY="sk-..."

# Deepgram (fÃ¼r --mode deepgram) â€“ 200$ Startguthaben
export DEEPGRAM_API_KEY="..."

# Groq (fÃ¼r --mode groq und --refine mit groq) â€“ kostenlose Credits
export GROQ_API_KEY="gsk_..."

# OpenRouter (Alternative fÃ¼r --refine) â€“ Hunderte Modelle
export OPENROUTER_API_KEY="sk-or-..."
```

### Standard-Einstellungen

```bash
# Transkriptions-Modus (openai, local, deepgram, groq)
export WHISPER_GO_MODE="deepgram"

# Transkriptions-Modell (Ã¼berschreibt Provider-Default)
export WHISPER_GO_MODEL="nova-3"

# Device fÃ¼r lokales Whisper (auto, mps, cpu, cuda)
# Standard: auto â†’ nutzt MPS auf Apple Silicon, sonst CPU/CUDA
export WHISPER_GO_DEVICE="auto"

# FP16 fÃ¼r lokales Whisper erzwingen (true/false)
# Standard: CPU/MPS â†’ false (stabil), CUDA â†’ true
export WHISPER_GO_FP16="false"

# Backend fÃ¼r lokales Whisper (whisper, faster, mlx, auto)
# whisper = openai-whisper (PyTorch, nutzt MPS/GPU)
# faster  = faster-whisper (CTranslate2, sehr schnell auf CPU)
# mlx     = mlx-whisper (MLX/Metal, Apple Silicon, optional)
# auto    = faster falls installiert, sonst whisper
export WHISPER_GO_LOCAL_BACKEND="whisper"

# Lokales Modell Ã¼berschreiben (nur fÃ¼r lokalen Modus)
# Standard: Provider-Default (turbo)
# export WHISPER_GO_LOCAL_MODEL="turbo"

# Compute-Type fÃ¼r faster-whisper (optional)
# Default: int8 auf CPU, float16 auf CUDA
# export WHISPER_GO_LOCAL_COMPUTE_TYPE="int8"

# Faster-whisper Threads (optional)
# 0 Threads = auto (alle Kerne)
# export WHISPER_GO_LOCAL_CPU_THREADS=0
# export WHISPER_GO_LOCAL_NUM_WORKERS=1

# Faster-whisper Optionen (optional)
# Standard bei faster: without_timestamps=true, vad_filter=false
# export WHISPER_GO_LOCAL_WITHOUT_TIMESTAMPS="true"
# export WHISPER_GO_LOCAL_VAD_FILTER="false"

# Optional: schnelleres lokales Decoding (mehr Speed, leicht weniger Robustheit)
# Standard: true bei faster-whisper, false bei openai-whisper
# export WHISPER_GO_LOCAL_FAST="true"  # setzt beam_size=1, best_of=1, temperature=0.0
# Feintuning:
# export WHISPER_GO_LOCAL_BEAM_SIZE=1
# export WHISPER_GO_LOCAL_BEST_OF=1
# export WHISPER_GO_LOCAL_TEMPERATURE=0.0

# Optional: Local Warmup (reduziert "cold start" beim ersten lokalen Call)
# Default: auto (Warmup nur bei openai-whisper auf MPS). Werte: true/false (nicht gesetzt = auto)
# export WHISPER_GO_LOCAL_WARMUP="true"

# WebSocket-Streaming fÃ¼r Deepgram (default: true)
export WHISPER_GO_STREAMING="true"

# LLM-Nachbearbeitung
export WHISPER_GO_REFINE="true"
export WHISPER_GO_REFINE_MODEL="gpt-5-nano"
export WHISPER_GO_REFINE_PROVIDER="openai"  # oder openrouter, groq
```

### System-AbhÃ¤ngigkeiten

FÃ¼r bestimmte Modi werden zusÃ¤tzliche Tools benÃ¶tigt:

```bash
# Lokaler Modus (Datei-Transkription)
# BenÃ¶tigt fÃ¼r `WHISPER_GO_LOCAL_BACKEND=whisper` und `mlx`, wenn Audiodateien transkribiert werden.
brew install ffmpeg          # macOS
sudo apt install ffmpeg      # Ubuntu/Debian

# Mikrofon-Aufnahme (macOS)
brew install portaudio
```

## Erweiterte Features

Ãœber die Basis-Transkription hinaus bietet whisper_go intelligente Nachbearbeitung und Anpassung.

### LLM-Nachbearbeitung

Entfernt FÃ¼llwÃ¶rter (Ã¤hm, also, quasi), korrigiert Grammatik und formatiert in saubere AbsÃ¤tze:

```bash
python transcribe.py --record --refine
```

UnterstÃ¼tzte Provider: OpenAI (default), [OpenRouter](https://openrouter.ai), [Groq](https://groq.com)

### Kontext-Awareness

Die Nachbearbeitung erkennt automatisch die aktive App und passt den Schreibstil an:

| Kontext   | Apps                      | Stil                            |
| --------- | ------------------------- | ------------------------------- |
| `email`   | Mail, Outlook, Spark      | Formell, vollstÃ¤ndige SÃ¤tze     |
| `chat`    | Slack, Discord, Messages  | Locker, kurz und knapp          |
| `code`    | VS Code, Cursor, Terminal | Technisch, Begriffe beibehalten |
| `default` | Alle anderen              | Standard-Korrektur              |

```bash
# Automatische Erkennung (Standard)
python transcribe.py --record --refine

# Manueller Override
python transcribe.py --record --refine --context email

# Eigene App-Mappings
export WHISPER_GO_APP_CONTEXTS='{"MyApp": "chat"}'
```

### Real-Time Audio Feedback

Das Overlay reagiert in Echtzeit auf die Stimme mit einer dynamischen Schallwellen-Visualisierung:

- **Listening (ðŸŒ¸ Rosa):** System wartet auf Spracheingabe.
- **Recording (ðŸ”´ Rot):** Sprache erkannt, Aufnahme lÃ¤uft. Die Balken visualisieren die LautstÃ¤rke.
- **Transcribing (ðŸŸ  Orange):** Aufnahme beendet, Text wird verarbeitet.

Dank integrierter Voice Activity Detection (VAD) schaltet der Status sofort um, sobald gesprochen wird.

### Sprach-Commands

Steuere Formatierung durch gesprochene Befehle (automatisch aktiv mit `--refine`):

| Deutsch          | Englisch           | Ergebnis |
| ---------------- | ------------------ | -------- |
| "neuer Absatz"   | "new paragraph"    | Absatz   |
| "neue Zeile"     | "new line"         | Umbruch  |
| "Punkt"          | "period"           | `.`      |
| "Komma"          | "comma"            | `,`      |
| "Fragezeichen"   | "question mark"    | `?`      |
| "Ausrufezeichen" | "exclamation mark" | `!`      |
| "Doppelpunkt"    | "colon"            | `:`      |
| "Semikolon"      | "semicolon"        | `;`      |

```bash
# Beispiel
python transcribe.py --record --refine
# Spreche: "Hallo Punkt wie geht es dir Fragezeichen"
# Ergebnis: "Hallo. Wie geht es dir?"
```

> **Hinweis:** Sprach-Commands werden vom LLM interpretiert â€“ sie funktionieren nur mit `--refine`.

### Custom Vocabulary

Eigene Begriffe fÃ¼r bessere Erkennung in `~/.whisper_go/vocabulary.json`:

```json
{
  "keywords": ["Anthropic", "Claude", "Kubernetes", "OAuth"]
}
```

UnterstÃ¼tzt von Deepgram und lokalem Whisper. Die OpenAI API unterstÃ¼tzt kein Custom Vocabulary â€“ dort hilft die LLM-Nachbearbeitung.

## Hotkey Integration

FÃ¼r systemweite Spracheingabe per Hotkey â€“ der Hauptanwendungsfall von whisper_go.

### Unified Daemon (empfohlen)

Der `whisper_daemon.py` kombiniert alle Komponenten in einem Prozess:

- Hotkey-Listener (QuickMacHotKey)
- Microphone Recording + Deepgram Streaming
- MenÃ¼bar-Status (ðŸŽ¤ ðŸ”´ â³ âœ… âŒ) - via `ui/menubar.py`
- Overlay mit Animationen - via `ui/overlay.py`
- Auto-Paste

```bash
# Manueller Start
python whisper_daemon.py

# Mit CLI-Optionen
python whisper_daemon.py --hotkey cmd+shift+r --debug

# Als Login Item (Doppelklick oder zu Anmeldeobjekten hinzufÃ¼gen)
open start_daemon.command
```

> **FÃ¼r Toggle-Hotkeys ist keine Accessibility-Berechtigung nÃ¶tig.** QuickMacHotKey nutzt die native Carbon-API (`RegisterEventHotKey`).  
> **Holdâ€‘Mode nutzt pynput und benÃ¶tigt Bedienungshilfen** unter macOS.

### Settings UI (MenÃ¼bar)

Ãœber das MenÃ¼bar-Icon â†’ **Settings...** kannst du Provider-Keys, Modus, Local Backend/Modell und erweiterte Local-Performance-Settings (Device, Warmup, Fast-Decoding, faster-whisper Compute/Threads, etc.) konfigurieren.  
Einstellungen werden in `~/.whisper_go/.env` gespeichert und live Ã¼bernommen (Hotkey-Ã„nderungen erfordern Neustart).

### Konfiguration

In `.env` oder als Umgebungsvariable:

```bash
# Hotkeys (default: Fn/Globe als Hold)
#
# Optional: Toggle + Hold parallel nutzen.
# Wenn gesetzt, Ã¼berschreibt dies WHISPER_GO_HOTKEY / WHISPER_GO_HOTKEY_MODE.
#
# Empfohlener Default: Fn/Globe als Pushâ€‘toâ€‘Talk (Hold).
# WHISPER_GO_HOLD_HOTKEY=fn
# Optional: separaten Toggleâ€‘Hotkey ergÃ¤nzen (z.B. F19).
# WHISPER_GO_TOGGLE_HOTKEY=f19
#
# Legacy (Single Hotkey):
WHISPER_GO_HOTKEY=fn
WHISPER_GO_HOTKEY_MODE=hold

# Dock-Icon (default: true) â€“ auf false setzen fÃ¼r Menubar-only Modus
WHISPER_GO_DOCK_ICON=true
```

**UnterstÃ¼tzte Hotkeys:**

| Format            | Beispiel              |
| ----------------- | --------------------- |
| Funktionstasten   | `f19`, `f1`, `f12`    |
| Einzeltaste       | `fn`, `capslock`, `space`, `tab`, `esc` |
| Tastenkombination | `cmd+shift+r`         |

**Empfohlene Hotkeyâ€‘Konfiguration (macOS):**

- **Fn/Globe als Holdâ€‘toâ€‘Record:** `WHISPER_GO_HOLD_HOTKEY=fn`.  
  Sehr schneller Pushâ€‘toâ€‘Talk Workflow mit einer Taste. BenÃ¶tigt Bedienungshilfen/Inputâ€‘Monitoring.
- **CapsLockâ€‘Alternative:** CapsLock geht direkt als Toggleâ€‘Hotkey, kollidiert aber oft mit der GroÃŸschreibung.  
  FÃ¼r einen konfliktfreien â€žEinâ€‘Tastenâ€‘Toggleâ€œ CapsLock per **Karabinerâ€‘Elements** auf `F19` mappen und `WHISPER_GO_TOGGLE_HOTKEY=f19` setzen.

### Nutzung

**Holdâ€‘Mode (Default / Pushâ€‘toâ€‘Talk):**

- Fn/Globe gedrÃ¼ckt halten â†’ Aufnahme lÃ¤uft solange gehalten
- Fn/Globe loslassen â†’ Transkript wird eingefÃ¼gt

**Toggleâ€‘Mode (Optional, z.B. mit F19):**

- F19 drÃ¼cken â†’ Aufnahme startet
- F19 nochmal drÃ¼cken â†’ Transkript wird eingefÃ¼gt

### Visuelles Feedback

Das Overlay zeigt den aktuellen Status durch Farben und Animationen an:

| Status           | Farbe      | Animation | Bedeutung                           |
| ---------------- | ---------- | --------- | ----------------------------------- |
| **Listening**    | ðŸŒ¸ Rosa    | Atmen     | Hotkey gedrÃ¼ckt, wartet auf Sprache |
| **Recording**    | ðŸ”´ Rot     | Wellen    | Sprache erkannt, Aufnahme lÃ¤uft     |
| **Transcribing** | ðŸŸ  Orange  | Laden     | Finalisierung der Transkription     |
| **Refining**     | ðŸ’œ Violett | Pulsieren | LLM-Nachbearbeitung lÃ¤uft           |
| **Done**         | âœ… GrÃ¼n    | HÃ¼pfen    | Fertig, Text eingefÃ¼gt              |
| **Error**        | âŒ Rot     | Blinken   | Fehler aufgetreten                  |

Beides ist integriert und startet automatisch mit dem Daemon.

## Provider-Vergleich

| Modus      | Provider | Methode   | Latenz    | Besonderheit                        |
| ---------- | -------- | --------- | --------- | ----------------------------------- |
| `deepgram` | Deepgram | WebSocket | ~300ms âš¡ | Echtzeit-Streaming (empfohlen)      |
| `groq`     | Groq     | REST      | ~1s       | Whisper auf LPU, sehr schnell       |
| `openai`   | OpenAI   | REST      | ~2-3s     | GPT-4o Transcribe, hÃ¶chste QualitÃ¤t |
| `local`    | Whisper  | Lokal     | variiert  | Offline, keine API-Kosten (Whisper / Faster / MLX) |

> **Empfehlung:** `--mode deepgram` fÃ¼r den tÃ¤glichen Gebrauch. Die Streaming-Architektur sorgt fÃ¼r minimale Wartezeit zwischen Aufnahme-Stopp und Text-EinfÃ¼gen.

## Modell-Referenz

### API-Modelle (OpenAI)

| Modell                   | Beschreibung         |
| ------------------------ | -------------------- |
| `gpt-4o-transcribe`      | Beste QualitÃ¤t â­    |
| `gpt-4o-mini-transcribe` | Schneller, gÃ¼nstiger |
| `whisper-1`              | Original Whisper     |

### Deepgram-Modelle

| Modell   | Beschreibung                       |
| -------- | ---------------------------------- |
| `nova-3` | Neuestes Modell, beste QualitÃ¤t â­ |
| `nova-2` | BewÃ¤hrtes Modell, gÃ¼nstiger        |

`smart_format` ist aktiviert â€“ automatische Formatierung von Datum, WÃ¤hrung und AbsÃ¤tzen.

#### Echtzeit-Streaming (Standard)

Deepgram nutzt standardmÃ¤ÃŸig **WebSocket-Streaming** fÃ¼r minimale Latenz:

- Audio wird **wÃ¤hrend der Aufnahme** transkribiert, nicht erst danach
- Ergebnis erscheint **sofort** nach dem Stoppen (statt 2-3s Wartezeit)
- Ideal fÃ¼r die Hotkey-Integration

```bash
# Streaming (Standard)
python transcribe.py --record --mode deepgram

# REST-Fallback (falls Streaming Probleme macht)
python transcribe.py --record --mode deepgram --no-streaming
# oder via ENV:
WHISPER_GO_STREAMING=false
```

### Groq-Modelle

| Modell                       | Beschreibung                        |
| ---------------------------- | ----------------------------------- |
| `whisper-large-v3`           | Whisper Large v3, ~300x Echtzeit â­ |
| `distil-whisper-large-v3-en` | Nur Englisch, noch schneller        |

Groq nutzt LPU-Chips (Language Processing Units) fÃ¼r besonders schnelle Inferenz.

### Lokale Modelle

Der lokale Modus unterstÃ¼tzt jetzt drei Backends:

- **`whisper` (Standard):** openaiâ€‘whisper auf PyTorch. Nutzt auf Mâ€‘Series Macs automatisch MPS (`WHISPER_GO_DEVICE=auto`). Beste KompatibilitÃ¤t/QualitÃ¤t.
- **`faster`:** fasterâ€‘whisper (CTranslate2). Sehr schnell auf CPU und mit weniger Speicherbedarf. Unter macOS lÃ¤uft es auf CPU (kein MPS/Metal). Defaultâ€‘`compute_type` ist `int8` auf CPU und `float16` auf CUDA. Aktivieren mit `WHISPER_GO_LOCAL_BACKEND=faster`.
- **`mlx`:** mlxâ€‘whisper (MLX/Metal). GPUâ€‘beschleunigtes lokales Backend auf Apple Silicon. Installieren mit `pip install mlx-whisper` und aktivieren via `WHISPER_GO_LOCAL_BACKEND=mlx`.

Hinweise:

- Modellname `turbo` wird bei fasterâ€‘whisper zu `large-v3-turbo` gemappt.
- FÃ¼r maximale Geschwindigkeit (mit leicht weniger Robustheit) `WHISPER_GO_LOCAL_FAST=true` oder kleinere `WHISPER_GO_LOCAL_BEAM_SIZE`/`WHISPER_GO_LOCAL_BEST_OF` wÃ¤hlen.
- FÃ¼r lÃ¤ngere Aufnahmen unter `faster` kannst du Durchsatz via `WHISPER_GO_LOCAL_CPU_THREADS` und `WHISPER_GO_LOCAL_NUM_WORKERS` tunen.
- FÃ¼r `mlx` wird `WHISPER_GO_LOCAL_BEAM_SIZE` ignoriert (Beam Search ist in mlxâ€‘whisper nicht implementiert).

#### Schnellstart (Offlineâ€‘Diktat)

Apple Silicon (empfohlenes lokales Backend):

```bash
pip install mlx-whisper
export WHISPER_GO_MODE=local
export WHISPER_GO_LOCAL_BACKEND=mlx
export WHISPER_GO_LOCAL_MODEL=large   # oder: turbo
export WHISPER_GO_LANGUAGE=de         # optional
python whisper_daemon.py --debug
```

#### Apple Silicon: MLX Modellnamen

Mit `WHISPER_GO_LOCAL_BACKEND=mlx` unterstÃ¼tzt `WHISPER_GO_LOCAL_MODEL` sowohl kurze Namen als auch vollstÃ¤ndige Huggingâ€‘Face Repoâ€‘IDs:

- `large` â†’ `mlx-community/whisper-large-v3-mlx`
- `turbo` â†’ `mlx-community/whisper-large-v3-turbo`
- `medium` â†’ `mlx-community/whisper-medium`
- `small` â†’ `mlx-community/whisper-small-mlx`
- `base` â†’ `mlx-community/whisper-base-mlx`
- `tiny` â†’ `mlx-community/whisper-tiny`

Wenn du vorher `whisper-large-v3` probiert hast und eine 404 bekommst, nutze `large`/`large-v3` oder die volle Repoâ€‘ID `mlx-community/whisper-large-v3-mlx`.

#### Warmup / cold start

Wenn der Daemon im `local`â€‘Modus lÃ¤uft, wird das lokale Modell im Hintergrund vorab geladen, um die erste Latenz zu reduzieren.  
Optional kannst du zusÃ¤tzlich ein Warmup via `WHISPER_GO_LOCAL_WARMUP=true` aktivieren (am nÃ¼tzlichsten fÃ¼r `whisper` auf MPS). Wenn du wÃ¤hrenddessen schon aufnimmst, wird nichts â€žverworfenâ€œ â€” die erste lokale Transkription kann nur trotzdem noch etwas Coldâ€‘Startâ€‘Overhead enthalten.

| Modell | Parameter | VRAM   | Geschwindigkeit  |
| ------ | --------- | ------ | ---------------- |
| tiny   | 39M       | ~1 GB  | Sehr schnell     |
| base   | 74M       | ~1 GB  | Schnell          |
| small  | 244M      | ~2 GB  | Mittel           |
| medium | 769M      | ~5 GB  | Langsam          |
| large  | 1550M     | ~10 GB | Sehr langsam     |
| turbo  | 809M      | ~6 GB  | Schnell & gut â­ |

â­ = Standard-Modell des Providers

## Troubleshooting

| Problem                                    | LÃ¶sung                                                                     |
| ------------------------------------------ | -------------------------------------------------------------------------- |
| Modul nicht installiert                    | `pip install -r requirements.txt`                                          |
| API-Key fehlt                              | `export DEEPGRAM_API_KEY="..."` (oder OPENAI/GROQ)                         |
| Mikrofon geht nicht (macOS)                | `brew install portaudio && pip install --force-reinstall sounddevice`      |
| Mikrofon-Berechtigung                      | Zugriff erlauben unter Systemeinstellungen â†’ Datenschutz â†’ Mikrofon        |
| ffmpeg fehlt                               | `brew install ffmpeg` (macOS) oder `sudo apt install ffmpeg` (Ubuntu) â€” nÃ¶tig fÃ¼r lokale Datei-Transkription (`whisper`/`mlx`) |
| MLX Modell-Download 404                    | `WHISPER_GO_LOCAL_MODEL=large` oder volle Repoâ€‘ID nutzen (z.B. `mlx-community/whisper-large-v3-mlx`) |
| Beam Search nicht implementiert (mlx)      | `WHISPER_GO_LOCAL_BEAM_SIZE` entfernen (wird bei `mlx` ignoriert) oder Backend wechseln |
| Transkription langsam                      | Wechsel zu `--mode groq`/`deepgram` oder lokal `WHISPER_GO_LOCAL_BACKEND=mlx` (Apple Silicon) / `faster` (CPU) und `WHISPER_GO_LOCAL_FAST=true` bzw. kleineres Modell |
| Daemon startet nicht                       | PrÃ¼fe `~/.whisper_go/startup.log` fÃ¼r Emergency-Logs                       |
| Auto-Paste funktioniert nicht (App Bundle) | Siehe [Auto-Paste Troubleshooting](#auto-paste-troubleshooting-app-bundle) |

### Auto-Paste Troubleshooting (App Bundle)

Wenn Auto-Paste in `WhisperGo.app` nicht funktioniert (Text wird kopiert, aber nicht eingefÃ¼gt):

**Zwischenablage:** WhisperGo stellt nach einem erfolgreichen Paste deine vorherige Zwischenablage wieder her. Wenn Paste fehlschlÃ¤gt, bleibt das Transkript in der Zwischenablage, damit du manuell `CMD+V` nutzen kannst.

**Symptom:** Log zeigt `AXIsProcessTrusted = False` obwohl App in Bedienungshilfen aktiviert ist.

**Ursache:** Unsignierte PyInstaller-Bundles Ã¤ndern bei jedem Neubuild ihren Hash. macOS erkennt die "neue" App nicht als berechtigt.

**LÃ¶sung:**

1. Systemeinstellungen â†’ Datenschutz & Sicherheit â†’ Bedienungshilfen
2. `WhisperGo` **entfernen** (Minus-Button)
3. `WhisperGo` **neu hinzufÃ¼gen** (Plus-Button oder App per Drag & Drop)

> **Tipp:** Nach jedem `pyinstaller build_app.spec` muss dieser Schritt wiederholt werden, solange die App nicht signiert ist.

### Log-Dateien

Logs werden in `~/.whisper_go/logs/` gespeichert:

```bash
# Haupt-Log
~/.whisper_go/logs/whisper_go.log

# Emergency Startup-Log (falls Daemon nicht startet)
~/.whisper_go/startup.log
```

**Diagnostics-Report:** MenÃ¼bar â†’ **Export Diagnosticsâ€¦** erstellt ein Zip unter `~/.whisper_go/diagnostics/` (API-Keys maskiert, Log-Tail redacted).

## Development

```bash
# Test-Dependencies installieren
pip install -r requirements-dev.txt

# Tests ausfÃ¼hren
pytest -v

# Mit Coverage-Report
pytest --cov=. --cov-report=term-missing
```

Tests laufen automatisch via GitHub Actions bei Push und Pull Requests.

### macOS App Bundle erstellen

Um eine eigenstÃ¤ndige `WhisperGo.app` zu erstellen:

```bash
# PyInstaller installieren (falls noch nicht vorhanden)
pip install pyinstaller

# App bauen
pyinstaller build_app.spec

# Output: dist/WhisperGo.app
```

**Optional: Code-Signierung fÃ¼r stabile Accessibility-Berechtigungen**

```bash
codesign --force --deep --sign - dist/WhisperGo.app
```

> **Hinweis:** Ohne Signierung muss die App nach jedem Neubuild in Systemeinstellungen â†’ Datenschutz & Sicherheit â†’ Bedienungshilfen neu autorisiert werden. Siehe [Auto-Paste Troubleshooting](#auto-paste-troubleshooting-app-bundle).

### DMG erstellen (fÃ¼r Distribution empfohlen)

```bash
# Dev (ad-hoc signiert)
./build_dmg.sh

# Release (Developer ID + Notarization)
export CODESIGN_IDENTITY="Developer ID Application: Dein Name (TEAMID)"
export NOTARY_PROFILE="whispergo-notary"
./build_dmg.sh 1.0.0 --notarize
```

Siehe `docs/BUILDING_MACOS.md` fÃ¼r die Notarization-Einrichtung.
