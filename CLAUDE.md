# Claude Code Projektanweisungen

## Projekt-Ãœbersicht

**whisper_go** â€“ Minimalistische Spracheingabe fÃ¼r macOS, inspiriert von [Wispr Flow](https://wisprflow.ai).

Siehe [docs/VISION.md](docs/VISION.md) fÃ¼r Roadmap und langfristige Ziele.

## Architektur

```
whisper_go/
â”œâ”€â”€ transcribe.py          # CLI fÃ¼r Transkription (Core-Logic)
â”œâ”€â”€ whisper_daemon.py      # Unified Daemon (Hotkey + Recording + UI)
â”œâ”€â”€ hotkey_daemon.py       # Standalone Hotkey-Daemon (Alternative)
â”œâ”€â”€ prompts.py             # LLM-Prompts und Kontext-Mappings
â”œâ”€â”€ start_daemon.command   # macOS Login Item fÃ¼r Auto-Start
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ README.md              # Benutzer-Dokumentation
â”œâ”€â”€ CLAUDE.md              # Diese Datei
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ VISION.md          # Produkt-Vision & Roadmap
â”‚   â”œâ”€â”€ Deepgram.md        # Deepgram Integration
â”‚   â””â”€â”€ WINDOWS_ANALYSIS.md
â””â”€â”€ tests/                 # Unit & Integration Tests (145+ Tests)
```

## Kern-Datei: `transcribe.py`

**Funktionen:**

| Funktion                            | Zweck                                          |
| ----------------------------------- | ---------------------------------------------- |
| `record_audio()`                    | Mikrofon-Aufnahme (interaktiv, mit ENTER)      |
| `record_audio_daemon()`             | Mikrofon-Aufnahme (Signal-basiert, Raycast)    |
| `play_sound(name)`                  | System-Sound abspielen (ready/stop/error)      |
| `transcribe()`                      | Zentrale API â€“ wÃ¤hlt Modus automatisch         |
| `transcribe_with_api()`             | OpenAI API Transkription                       |
| `transcribe_with_deepgram()`        | Deepgram Nova-3 Transkription (REST)           |
| `transcribe_with_deepgram_stream()` | Deepgram Streaming (WebSocket, SDK v5.3)       |
| `transcribe_with_groq()`            | Groq Whisper Transkription (LPU)               |
| `transcribe_locally()`              | Lokales Whisper-Modell                         |
| `detect_context()`                  | Kontext-Erkennung (CLI/ENV/App-Auto-Detection) |
| `_get_frontmost_app()`              | Aktive App via NSWorkspace (macOS, ~0.2ms)     |
| `_app_to_context()`                 | App-Name â†’ Kontext-Typ Mapping                 |
| `refine_transcript()`               | LLM-Nachbearbeitung (kontext-aware Prompts)    |
| `_get_refine_client()`              | Client-Factory fÃ¼r Refine-Provider             |
| `run_daemon_mode()`                 | Raycast-Modus: Aufnahme â†’ Transkript-Datei     |
| `run_daemon_mode_streaming()`       | Raycast-Modus mit Deepgram Streaming           |
| `_daemonize()`                      | Double-Fork fÃ¼r echte Daemons (Zombie-Prev.)   |
| `_cleanup_stale_pid_file()`         | Zombie-Prozess Cleanup mit PID-Validierung     |
| `parse_args()`                      | CLI-Argument-Handling                          |

**Design-Entscheidungen:**

- Lazy Imports: `openai`, `whisper`, `sounddevice` werden erst bei Bedarf importiert
- Stderr fÃ¼r Status, Stdout nur fÃ¼r Output â†’ saubere Pipe-Nutzung
- Eine Datei statt mehrere â†’ KISS-Prinzip
- Flache Struktur mit Early Returns
- Double-Fork Daemon: Verhindert Zombies bei Raycast spawn+unref

## Unified Daemon: `whisper_daemon.py`

Konsolidiert alle Komponenten in einem Prozess (empfohlen fÃ¼r tÃ¤gliche Nutzung):

**Klassen:**

| Klasse | Zweck |
| ------ | ----- |
| `MenuBarController` | MenÃ¼bar-Status via NSStatusBar (ðŸŽ¤ ðŸ”´ â³ âœ… âŒ) |
| `OverlayController` | Animiertes Overlay am unteren Bildschirmrand |
| `SoundWaveView` | Animierte Schallwellen-Visualisierung (Recording/Loading) |
| `WhisperDaemon` | Hauptklasse: Hotkey + Recording + Streaming + UI |

**Architektur:**

- **Main-Thread:** Hotkey-Listener (QuickMacHotKey) + UI-Updates
- **Worker-Thread:** Deepgram-Streaming (async)

**State-Flow:** `idle` â†’ `recording` â†’ `transcribing` â†’ `done`/`error` â†’ `idle`

## Hotkey-Daemon: `hotkey_daemon.py`

Standalone-Alternative fÃ¼r Raycast-Integration:

| Funktion | Zweck |
| -------- | ----- |
| `parse_hotkey()` | Parst Hotkey-String (z.B. "cmd+shift+r") |
| `paste_transcript()` | Auto-Paste via pynput/Quartz/osascript |
| `HotkeyDaemon` | Globaler Hotkey-Listener (QuickMacHotKey) |

## CLI-Interface

```bash
# Datei transkribieren
python transcribe.py audio.mp3
python transcribe.py audio.mp3 --mode local --model large

# Mikrofon-Aufnahme
python transcribe.py --record --copy --language de
```

## Dependencies

| Paket            | Zweck                                     |
| ---------------- | ----------------------------------------- |
| `openai`         | API-Modus + LLM-Refine (OpenRouter)       |
| `openai-whisper` | Lokaler Modus                             |
| `deepgram-sdk`   | Deepgram Nova-3 Transkription (REST + WS) |
| `groq`           | Groq Whisper + LLM-Refine                 |
| `sounddevice`    | Mikrofon-Aufnahme                         |
| `soundfile`      | WAV-Export                                |
| `pyperclip`      | Zwischenablage                            |
| `python-dotenv`  | .env Konfiguration                        |
| `rumps`          | MenÃ¼bar-App                               |
| `quickmachotkey` | Globale Hotkeys (Carbon API, kein TCC)    |

**Externe:**

- `ffmpeg` (fÃ¼r lokalen Modus)
- `portaudio` (fÃ¼r Mikrofon auf macOS)

## Konfiguration (ENV-Variablen)

| Variable                     | Beschreibung                                          |
| ---------------------------- | ----------------------------------------------------- |
| `WHISPER_GO_MODE`            | Default-Modus: `api`, `local`, `deepgram`, `groq`     |
| `WHISPER_GO_MODEL`           | Transkriptions-Modell (Ã¼berschreibt Provider-Default) |
| `WHISPER_GO_STREAMING`       | WebSocket-Streaming fÃ¼r Deepgram: `true`/`false`      |
| `WHISPER_GO_REFINE`          | LLM-Nachbearbeitung: `true`/`false`                   |
| `WHISPER_GO_REFINE_MODEL`    | Modell fÃ¼r Refine (default: `gpt-5-nano`)             |
| `WHISPER_GO_REFINE_PROVIDER` | Provider: `openai`, `openrouter` oder `groq`          |
| `WHISPER_GO_CONTEXT`         | Kontext-Override: `email`/`chat`/`code`               |
| `WHISPER_GO_APP_CONTEXTS`    | Custom App-Mappings (JSON)                            |
| `WHISPER_GO_OVERLAY`         | Untertitel-Overlay aktivieren: `true`/`false`         |
| `OPENAI_API_KEY`             | FÃ¼r API-Modus und OpenAI-Refine                       |
| `DEEPGRAM_API_KEY`           | FÃ¼r Deepgram-Modus (REST + Streaming)                 |
| `GROQ_API_KEY`               | FÃ¼r Groq-Modus und Groq-Refine                        |
| `OPENROUTER_API_KEY`         | FÃ¼r OpenRouter-Refine                                 |

## Transkriptions-Modi

| Modus                     | Provider | Methode   | Latenz | Beschreibung                             |
| ------------------------- | -------- | --------- | ------ | ---------------------------------------- |
| `api`                     | OpenAI   | REST      | ~2-3s  | GPT-4o Transcribe, hÃ¶chste QualitÃ¤t      |
| `deepgram`                | Deepgram | WebSocket | ~300ms | **Streaming** (Default), minimale Latenz |
| `deepgram --no-streaming` | Deepgram | REST      | ~2-3s  | Fallback ohne Streaming                  |
| `groq`                    | Groq     | REST      | ~1s    | Whisper auf LPU, sehr schnell            |
| `local`                   | Whisper  | Lokal     | ~5-10s | Offline, keine API-Kosten                |

## Kontext-Awareness

Die LLM-Nachbearbeitung passt den Prompt automatisch an den Nutzungskontext an:

| Kontext   | Stil                            | Apps (Beispiele)         |
| --------- | ------------------------------- | ------------------------ |
| `email`   | Formell, vollstÃ¤ndige SÃ¤tze     | Mail, Outlook, Spark     |
| `chat`    | Locker, kurz und knapp          | Slack, Discord, Messages |
| `code`    | Technisch, Begriffe beibehalten | VS Code, Cursor, iTerm   |
| `default` | Standard-Korrektur              | Alle anderen             |

**PrioritÃ¤t:** CLI (`--context`) > ENV (`WHISPER_GO_CONTEXT`) > App-Auto-Detection > Default

**Performance:** NSWorkspace-API (~0.2ms) statt AppleScript (~207ms)

## Sprach-Commands

Voice-Commands werden vom LLM in der Refine-Pipeline interpretiert (nur mit `--refine`):

| Befehl (DE/EN)                   | Ergebnis |
| -------------------------------- | -------- |
| "neuer Absatz" / "new paragraph" | `\n\n`   |
| "neue Zeile" / "new line"        | `\n`     |
| "Punkt" / "period"               | `.`      |
| "Komma" / "comma"                | `,`      |
| "Fragezeichen" / "question mark" | `?`      |

**Implementierung:** `prompts.py` â†’ `VOICE_COMMANDS_INSTRUCTION` wird automatisch in alle Prompts eingefÃ¼gt via `get_prompt_for_context(context, voice_commands=True)`

## Entwicklungs-Konventionen

- Python 3.10+ (Type Hints mit `|` statt `Union`)
- Keine unnÃ¶tigen Abstraktionen
- Fehler â†’ stderr, Ergebnis â†’ stdout
- Deutsche CLI-Ausgaben (Zielgruppe)
- Atomare, kleine Commits
