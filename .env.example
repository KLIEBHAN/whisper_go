# API Keys für PulseScribe
# Kopiere diese Datei nach .env und füge deine Keys ein

# Standard-Modus (openai, local, deepgram, groq)
PULSESCRIBE_MODE=deepgram

# Transkriptions-Modell (optional, überschreibt Provider-Default)
# API: gpt-4o-transcribe | Deepgram: nova-3 | Groq: whisper-large-v3 | Lokal: turbo
# PULSESCRIBE_MODEL=nova-3

# =============================================================================
# Lokaler Modus (Whisper offline)
# =============================================================================

# Backend (whisper = openai-whisper/PyTorch, faster = faster-whisper/CTranslate2, mlx = mlx-whisper/Metal (Apple Silicon), auto)
# PULSESCRIBE_LOCAL_BACKEND=whisper

# Lokales Modell (nur local mode). Default: turbo
# PULSESCRIBE_LOCAL_MODEL=turbo

# Device für openai-whisper (auto, mps, cpu, cuda)
# PULSESCRIBE_DEVICE=auto

# FP16 für openai-whisper erzwingen (true/false)
# PULSESCRIBE_FP16=false

# Optional: schnelleres Decoding
# PULSESCRIBE_LOCAL_FAST=false
# PULSESCRIBE_LOCAL_BEAM_SIZE=1
# PULSESCRIBE_LOCAL_BEST_OF=1
# PULSESCRIBE_LOCAL_TEMPERATURE=0.0

# Optional: Compute-Type für faster-whisper (Default CPU=int8, CUDA=float16)
# PULSESCRIBE_LOCAL_COMPUTE_TYPE=int8

# Optional: faster-whisper Threads/Optionen
# PULSESCRIBE_LOCAL_CPU_THREADS=0
# PULSESCRIBE_LOCAL_NUM_WORKERS=1
# PULSESCRIBE_LOCAL_WITHOUT_TIMESTAMPS=true
# PULSESCRIBE_LOCAL_VAD_FILTER=false

# Optional: Local Warmup (reduziert "cold start" Latenz bei erstem Local-Call)
# Default: auto (warmup nur bei openai-whisper auf MPS). Werte: true/false (nicht gesetzt = auto)
# PULSESCRIBE_LOCAL_WARMUP=true

# Sprache für Transkription (optional, default: auto-detect)
# Sprachcodes: de, en, fr, es, etc.
# PULSESCRIBE_LANGUAGE=de

# LLM-Nachbearbeitung (Flow-Style: Füllwörter entfernen, Grammatik korrigieren)
PULSESCRIBE_REFINE=true
PULSESCRIBE_REFINE_MODEL=openai/gpt-oss-120b

# LLM-Provider für Nachbearbeitung (openai, openrouter, groq, gemini)
PULSESCRIBE_REFINE_PROVIDER=groq

# OpenAI API (für --mode openai und --refine mit openai)
OPENAI_API_KEY=sk-...

# Deepgram API (für --mode deepgram)
# 200$ Startguthaben: https://console.deepgram.com
DEEPGRAM_API_KEY=...

# Groq API (für --mode groq und --refine mit groq)
# Extrem schnelle Whisper-Inferenz (~300x Echtzeit): https://console.groq.com
GROQ_API_KEY=gsk_...

# OpenRouter API (Alternative für --refine)
# Hunderte Modelle über eine API: https://openrouter.ai
OPENROUTER_API_KEY=sk-or-...

# Google Gemini API (für --refine mit gemini)
# https://aistudio.google.com/apikey
GEMINI_API_KEY=...

# OpenRouter Provider-Routing (optional)
# Steuert welche Backend-Provider OpenRouter nutzt
# Verfügbar: Together, DeepInfra, Fireworks, Lepton, Mancer, etc.
# OPENROUTER_PROVIDER_ORDER=Together,DeepInfra
# OPENROUTER_ALLOW_FALLBACKS=true

# =============================================================================
# Hotkey-Daemon (pynput)
# =============================================================================

# Hotkeys für Aufnahme (default: fn/hold)
# Einzeltasten: f1-f20, fn, capslock, space, enter, tab, esc
# Kombinationen: ctrl+shift+space, cmd+r
#
# Optional: Toggle und Hold parallel nutzen.
# Wenn gesetzt, überschreibt dies PULSESCRIBE_HOTKEY / PULSESCRIBE_HOTKEY_MODE.
# PULSESCRIBE_TOGGLE_HOTKEY=capslock
# PULSESCRIBE_HOLD_HOTKEY=fn
#
# Legacy (Single Hotkey):
PULSESCRIBE_HOTKEY=fn
PULSESCRIBE_HOTKEY_MODE=hold
