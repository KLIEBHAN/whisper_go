#!/usr/bin/env python3
"""
whisper_go ‚Äì Audio-Transkription mit OpenAI Whisper.

Unterst√ºtzt sowohl die OpenAI API als auch lokale Whisper-Modelle.
Transkripte werden auf stdout ausgegeben, Status auf stderr.

Usage:
    python transcribe.py audio.mp3
    python transcribe.py audio.mp3 --mode local
    python transcribe.py --record --copy
"""

import argparse
import os
import signal
import sys
import tempfile
from pathlib import Path

# Whisper erwartet Audio mit 16kHz ‚Äì andere Sampleraten f√ºhren zu schlechteren Ergebnissen
WHISPER_SAMPLE_RATE = 16000

DEFAULT_API_MODEL = "gpt-4o-transcribe"
DEFAULT_LOCAL_MODEL = "turbo"

TEMP_RECORDING_FILENAME = "whisper_recording.wav"

# Daemon-Modus: Dateien f√ºr IPC mit Raycast
PID_FILE = Path("/tmp/whisper_go.pid")
TRANSCRIPT_FILE = Path("/tmp/whisper_go.transcript")
ERROR_FILE = Path("/tmp/whisper_go.error")


def log(message: str) -> None:
    """Status-Meldung auf stderr (h√§lt stdout sauber f√ºr Pipes)."""
    print(message, file=sys.stderr)


def error(message: str) -> None:
    """Fehlermeldung auf stderr."""
    print(f"Fehler: {message}", file=sys.stderr)


def load_environment() -> None:
    """
    L√§dt .env-Datei falls python-dotenv installiert ist.
    Sucht in: 1) Script-Verzeichnis (Symlinks aufgel√∂st), 2) Aktuelles Verzeichnis
    """
    try:
        from dotenv import load_dotenv

        # .env im Script-Verzeichnis (resolve() folgt Symlinks)
        script_dir = Path(__file__).resolve().parent
        env_file = script_dir / ".env"
        if env_file.exists():
            load_dotenv(env_file)
        else:
            # Fallback: aktuelles Verzeichnis
            load_dotenv()
    except ImportError:
        pass


def copy_to_clipboard(text: str) -> bool:
    """Kopiert Text in die Zwischenablage. Gibt True bei Erfolg zur√ºck."""
    try:
        import pyperclip

        pyperclip.copy(text)
        return True
    except Exception:
        return False


def record_audio() -> Path:
    """
    Nimmt Audio vom Mikrofon auf (Enter startet, Enter stoppt).
    Gibt Pfad zur tempor√§ren WAV-Datei zur√ºck.
    """
    import numpy as np
    import sounddevice as sd
    import soundfile as sf

    recorded_chunks: list = []

    def on_audio_chunk(indata, frames, time, status):
        recorded_chunks.append(indata.copy())

    log("üé§ Dr√ºcke ENTER um die Aufnahme zu starten...")
    input()

    log("üî¥ Aufnahme l√§uft... Dr√ºcke ENTER zum Beenden.")
    with sd.InputStream(
        samplerate=WHISPER_SAMPLE_RATE,
        channels=1,
        dtype="float32",
        callback=on_audio_chunk,
    ):
        input()

    log("‚úÖ Aufnahme beendet.")

    if not recorded_chunks:
        raise ValueError("Keine Audiodaten aufgenommen. Bitte l√§nger aufnehmen.")

    audio_data = np.concatenate(recorded_chunks)
    output_path = Path(tempfile.gettempdir()) / TEMP_RECORDING_FILENAME
    sf.write(output_path, audio_data, WHISPER_SAMPLE_RATE)

    return output_path


def record_audio_daemon() -> Path:
    """
    Daemon-Modus: Nimmt Audio auf bis SIGUSR1 empfangen wird.
    Schreibt PID-File f√ºr externe Steuerung (Raycast).
    Kein globaler State ‚Äì verwendet Closure f√ºr Signal-Flag.
    """
    import numpy as np
    import sounddevice as sd
    import soundfile as sf

    recorded_chunks: list = []
    stop_flag = {"stop": False}  # Mutable Container statt global

    def on_audio_chunk(indata, frames, time, status):
        recorded_chunks.append(indata.copy())

    def handle_stop_signal(signum: int, frame) -> None:
        stop_flag["stop"] = True

    # PID-File schreiben f√ºr Raycast
    PID_FILE.write_text(str(os.getpid()))

    # Signal-Handler registrieren
    signal.signal(signal.SIGUSR1, handle_stop_signal)

    log("üé§ Daemon: Aufnahme gestartet (warte auf SIGUSR1)...")

    try:
        with sd.InputStream(
            samplerate=WHISPER_SAMPLE_RATE,
            channels=1,
            dtype="float32",
            callback=on_audio_chunk,
        ):
            while not stop_flag["stop"]:
                sd.sleep(100)  # 100ms warten, dann Signal pr√ºfen
    finally:
        # PID-File aufr√§umen
        if PID_FILE.exists():
            PID_FILE.unlink()

    log("‚úÖ Daemon: Aufnahme beendet.")

    if not recorded_chunks:
        raise ValueError("Keine Audiodaten aufgenommen.")

    audio_data = np.concatenate(recorded_chunks)
    output_path = Path(tempfile.gettempdir()) / TEMP_RECORDING_FILENAME
    sf.write(output_path, audio_data, WHISPER_SAMPLE_RATE)

    return output_path


def transcribe_with_api(
    audio_path: Path,
    model: str,
    language: str | None = None,
    response_format: str = "text",
) -> str:
    """Transkribiert Audio √ºber die OpenAI API."""
    from openai import OpenAI

    client = OpenAI()

    with audio_path.open("rb") as audio_file:
        params = {
            "model": model,
            "file": audio_file,
            "response_format": response_format,
        }
        if language:
            params["language"] = language
        response = client.audio.transcriptions.create(**params)

    # API gibt bei format="text" String zur√ºck, sonst Objekt
    if response_format == "text":
        return response
    return response.text if hasattr(response, "text") else str(response)


def transcribe_locally(
    audio_path: Path,
    model: str,
    language: str | None = None,
) -> str:
    """Transkribiert Audio lokal mit openai-whisper."""
    import whisper

    log(f"Lade Modell '{model}'...")
    whisper_model = whisper.load_model(model)

    log(f"Transkribiere {audio_path.name}...")
    options = {"language": language} if language else {}
    result = whisper_model.transcribe(str(audio_path), **options)

    return result["text"]


def transcribe(
    audio_path: Path,
    mode: str,
    model: str | None = None,
    language: str | None = None,
    response_format: str = "text",
) -> str:
    """
    Zentrale Transkriptions-Funktion ‚Äì w√§hlt API oder lokal.

    Dies ist der einzige Einstiegspunkt f√ºr Transkription,
    unabh√§ngig vom gew√§hlten Modus.
    """
    effective_model = model or (
        DEFAULT_API_MODEL if mode == "api" else DEFAULT_LOCAL_MODEL
    )

    if mode == "api":
        return transcribe_with_api(
            audio_path, effective_model, language, response_format
        )

    if response_format != "text":
        log("Hinweis: --format wird im lokalen Modus ignoriert")

    return transcribe_locally(audio_path, effective_model, language)


def parse_args() -> argparse.Namespace:
    """Parst und validiert CLI-Argumente."""
    parser = argparse.ArgumentParser(
        description="Audio transkribieren mit Whisper (API oder lokal)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Beispiele:
  %(prog)s audio.mp3
  %(prog)s audio.mp3 --mode local --model large
  %(prog)s --record --copy --language de
        """,
    )

    parser.add_argument("audio", type=Path, nargs="?", help="Pfad zur Audiodatei")
    parser.add_argument(
        "-r", "--record", action="store_true", help="Vom Mikrofon aufnehmen"
    )
    parser.add_argument(
        "--record-daemon",
        action="store_true",
        help="Daemon-Modus: Aufnahme bis SIGUSR1 (f√ºr Raycast)",
    )
    parser.add_argument(
        "-c", "--copy", action="store_true", help="Ergebnis in Zwischenablage"
    )
    parser.add_argument(
        "--mode", choices=["api", "local"], default="api", help="Transkriptions-Modus"
    )
    parser.add_argument(
        "--model",
        help="Modellname (API: gpt-4o-transcribe; Lokal: tiny, base, small, medium, large, turbo)",
    )
    parser.add_argument("--language", help="Sprachcode z.B. 'de', 'en'")
    parser.add_argument(
        "--format",
        dest="response_format",
        choices=["text", "json", "srt", "vtt"],
        default="text",
    )

    args = parser.parse_args()

    # Validierung: genau eine Audio-Quelle erforderlich
    has_audio_source = args.record or args.record_daemon or args.audio is not None
    if not has_audio_source:
        parser.error("Entweder Audiodatei, --record oder --record-daemon verwenden")

    # Gegenseitiger Ausschluss
    if args.audio and (args.record or args.record_daemon):
        parser.error("Audiodatei und Aufnahme-Modi schlie√üen sich aus")
    if args.record and args.record_daemon:
        parser.error("--record und --record-daemon schlie√üen sich aus")

    return args


def run_daemon_mode(args: argparse.Namespace) -> int:
    """
    Daemon-Modus f√ºr Raycast: Aufnahme ‚Üí Transkription ‚Üí Datei.
    Schreibt Fehler in ERROR_FILE f√ºr besseres Feedback.
    """
    temp_file: Path | None = None

    # Alte Error-Datei aufr√§umen
    if ERROR_FILE.exists():
        ERROR_FILE.unlink()

    try:
        audio_path = record_audio_daemon()
        temp_file = audio_path

        transcript = transcribe(
            audio_path,
            mode=args.mode,
            model=args.model,
            language=args.language,
            response_format=args.response_format,
        )

        TRANSCRIPT_FILE.write_text(transcript)
        print(transcript)

        if args.copy:
            copy_to_clipboard(transcript)

        return 0

    except ImportError:
        msg = "F√ºr Aufnahme: pip install sounddevice soundfile"
        error(msg)
        ERROR_FILE.write_text(msg)
        return 1
    except Exception as e:
        error(str(e))
        ERROR_FILE.write_text(str(e))
        return 1
    finally:
        if temp_file and temp_file.exists():
            temp_file.unlink()


def main() -> int:
    """CLI-Einstiegspunkt."""
    load_environment()
    args = parse_args()

    # Daemon-Modus hat eigene Logik (f√ºr Raycast)
    if args.record_daemon:
        return run_daemon_mode(args)

    # Audio-Quelle bestimmen
    temp_file: Path | None = None

    if args.record:
        try:
            audio_path = record_audio()
            temp_file = audio_path
        except ImportError:
            error("F√ºr Aufnahme: pip install sounddevice soundfile")
            return 1
        except ValueError as e:
            error(str(e))
            return 1
    else:
        audio_path = args.audio
        if not audio_path.exists():
            error(f"Datei nicht gefunden: {audio_path}")
            return 1

    # Transkription durchf√ºhren
    try:
        transcript = transcribe(
            audio_path,
            mode=args.mode,
            model=args.model,
            language=args.language,
            response_format=args.response_format,
        )
    except ImportError as e:
        package = "openai" if "openai" in str(e) else "openai-whisper"
        error(f"Modul nicht installiert: pip install {package}")
        return 1
    except Exception as e:
        error(str(e))
        return 1
    finally:
        if temp_file and temp_file.exists():
            temp_file.unlink()

    # Ausgabe
    print(transcript)

    if args.copy:
        if copy_to_clipboard(transcript):
            log("üìã In Zwischenablage kopiert!")
        else:
            log("‚ö†Ô∏è  Zwischenablage nicht verf√ºgbar")

    return 0


if __name__ == "__main__":
    sys.exit(main())
